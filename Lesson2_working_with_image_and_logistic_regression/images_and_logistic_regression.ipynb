{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "images_and_logistic_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5523222af4a74697ab088543de175f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4cb16439dff04d949c3036c0b8feeb00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09b234e523744494adbf61753c8d293f",
              "IPY_MODEL_d72ba93ac7f840b3ae95e9a7b5f38b53"
            ]
          }
        },
        "4cb16439dff04d949c3036c0b8feeb00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09b234e523744494adbf61753c8d293f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83ac3f2361c3459394c222f923df8a88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_197cfc09b3d24b9a9f93f36b4ddaf8d8"
          }
        },
        "d72ba93ac7f840b3ae95e9a7b5f38b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0040d934e1e47e6b73254173de2555a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [24:46&lt;00:00, 6670.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_260842ac39cc4c1585284944f3d788ac"
          }
        },
        "83ac3f2361c3459394c222f923df8a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "197cfc09b3d24b9a9f93f36b4ddaf8d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0040d934e1e47e6b73254173de2555a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "260842ac39cc4c1585284944f3d788ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f0f6ef3f9b64d02b75f38e1eeafba09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4727a57d4a3c4c7e9dd6be8e53f025f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d7bd17ef6ed4a83b27fcc7fb8e70562",
              "IPY_MODEL_b627eb4424d34bbb9498ab370d228531"
            ]
          }
        },
        "4727a57d4a3c4c7e9dd6be8e53f025f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d7bd17ef6ed4a83b27fcc7fb8e70562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5dd98a3c12a44f42bbaa1208d5ad5295",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d134472d4884627bd79adb2477c250a"
          }
        },
        "b627eb4424d34bbb9498ab370d228531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_145e9b03eb8143fea35a2d5ed60565bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [01:43&lt;00:00, 287.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f91a6279124744cc8b01477832c315b5"
          }
        },
        "5dd98a3c12a44f42bbaa1208d5ad5295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d134472d4884627bd79adb2477c250a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "145e9b03eb8143fea35a2d5ed60565bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f91a6279124744cc8b01477832c315b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5989b7c06836460d885a428f37c6a953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93756679031b48fb89663df67d6e2ff0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_caf8c5ffe5ea4759ac5bf8e1569d41b9",
              "IPY_MODEL_1bf460007bce494699a5c83de3a92b6b"
            ]
          }
        },
        "93756679031b48fb89663df67d6e2ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "caf8c5ffe5ea4759ac5bf8e1569d41b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0443e584a07644e1ace9775f5eda744b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a9940cffeba49edabd20a530bb99739"
          }
        },
        "1bf460007bce494699a5c83de3a92b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73971657307b49ffa841e17f68b3a2f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:51&lt;00:00, 31922.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70cb5ae2d2884099a7b264f8448d1c72"
          }
        },
        "0443e584a07644e1ace9775f5eda744b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a9940cffeba49edabd20a530bb99739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73971657307b49ffa841e17f68b3a2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70cb5ae2d2884099a7b264f8448d1c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1400d8966d154e6a9ba4ace234c958e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a96653e42de54f4fb2095ee5180f9851",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4d89017f3a248469eb921114899a806",
              "IPY_MODEL_54ad6bb4fc34483fbcc7e5a03c2108de"
            ]
          }
        },
        "a96653e42de54f4fb2095ee5180f9851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4d89017f3a248469eb921114899a806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36e80687fac24447a1533701854f0828",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fff28c94837542a384fbcbfd45d9c261"
          }
        },
        "54ad6bb4fc34483fbcc7e5a03c2108de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cfe65df8d6244fceb6829e31b26e4420",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 16369.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5060f7f0903490388759312e1124d48"
          }
        },
        "36e80687fac24447a1533701854f0828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fff28c94837542a384fbcbfd45d9c261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfe65df8d6244fceb6829e31b26e4420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5060f7f0903490388759312e1124d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5somNdBTWU_",
        "outputId": "a33c344a-a487-4f03-d3c8-bb407bac1ebb"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('images-and-logistic-regression')\n",
        "jovian.set_colab_id('1FxIVEDF6a40afssoTx3In8flpiPcoZqF')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▉                           | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 30kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQdIVxRj_W0v"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K85qxRZj_W0w"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "5523222af4a74697ab088543de175f2f",
            "4cb16439dff04d949c3036c0b8feeb00",
            "09b234e523744494adbf61753c8d293f",
            "d72ba93ac7f840b3ae95e9a7b5f38b53",
            "83ac3f2361c3459394c222f923df8a88",
            "197cfc09b3d24b9a9f93f36b4ddaf8d8",
            "d0040d934e1e47e6b73254173de2555a",
            "260842ac39cc4c1585284944f3d788ac",
            "6f0f6ef3f9b64d02b75f38e1eeafba09",
            "4727a57d4a3c4c7e9dd6be8e53f025f9",
            "4d7bd17ef6ed4a83b27fcc7fb8e70562",
            "b627eb4424d34bbb9498ab370d228531",
            "5dd98a3c12a44f42bbaa1208d5ad5295",
            "6d134472d4884627bd79adb2477c250a",
            "145e9b03eb8143fea35a2d5ed60565bd",
            "f91a6279124744cc8b01477832c315b5",
            "5989b7c06836460d885a428f37c6a953",
            "93756679031b48fb89663df67d6e2ff0",
            "caf8c5ffe5ea4759ac5bf8e1569d41b9",
            "1bf460007bce494699a5c83de3a92b6b",
            "0443e584a07644e1ace9775f5eda744b",
            "9a9940cffeba49edabd20a530bb99739",
            "73971657307b49ffa841e17f68b3a2f0",
            "70cb5ae2d2884099a7b264f8448d1c72",
            "1400d8966d154e6a9ba4ace234c958e4",
            "a96653e42de54f4fb2095ee5180f9851",
            "f4d89017f3a248469eb921114899a806",
            "54ad6bb4fc34483fbcc7e5a03c2108de",
            "36e80687fac24447a1533701854f0828",
            "fff28c94837542a384fbcbfd45d9c261",
            "cfe65df8d6244fceb6829e31b26e4420",
            "a5060f7f0903490388759312e1124d48"
          ]
        },
        "id": "1XlomM6D_zYL",
        "outputId": "3c4c9365-bbfd-4d1d-813a-9b573996f0f8"
      },
      "source": [
        "# Download training dataset\n",
        "dataset = MNIST(root='data/', download=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5523222af4a74697ab088543de175f2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f0f6ef3f9b64d02b75f38e1eeafba09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5989b7c06836460d885a428f37c6a953",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1400d8966d154e6a9ba4ace234c958e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kllQ4IrVApiv"
      },
      "source": [
        "When this statement is executed for the first time, it downloads the data to the data/ directory next to the notebook and creates a PyTorch Dataset. On subsequent executions, the download is skipped as the data is already downloaded. Let's check the size of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-_X1Cq-JAOD-",
        "outputId": "90213e2c-757c-43a3-c3f5-f9882accb9f4"
      },
      "source": [
        "size = len(dataset)\n",
        "f\"training data size: {size}\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training data size: 60000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhPayl0NBb2g"
      },
      "source": [
        "The dataset has 60,000 images that we'll use to train the model. There is also an additional test set of 10,000 images used for evaluating models and reporting metrics in papers and reports. We can create the test dataset using the MNIST class by passing train=False to the constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AebH5wJhAsii",
        "outputId": "b1fa64df-7338-48f6-e85f-6f0ec4d36867"
      },
      "source": [
        "test_dataset = MNIST(root='data/', train=False)\n",
        "ds_test_size = len(test_dataset)\n",
        "f\"testing data size: {ds_test_size}\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'testing data size: 10000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZecLutD2C0aE"
      },
      "source": [
        "Let's look at a sample element from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaVkaGwPBx2l",
        "outputId": "fa8f578f-faeb-4c87-d005-eb4f807fb2e5"
      },
      "source": [
        "dataset[-1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F54C27323D0>, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECwOnE_hDhJp"
      },
      "source": [
        "It's a pair, consisting of a 28x28px image and a label. The image is an object of the class `PIL.Image.Image`, which is a part of the Python imaging library [Pillow](https://pillow.readthedocs.io/en/stable/). We can view the image within Jupyter using `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vxiQMGDRK6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxxNHKI5EB9Z"
      },
      "source": [
        "Let's look at a couple of images from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "AQYxu3P3Du3Q",
        "outputId": "f75d4ea9-0714-4829-aa13-94034c696e87"
      },
      "source": [
        "image, label = dataset[5]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print(f'label: {label}')\n",
        "print('**' * 10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: 2\n",
            "********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GM7HEGrsEfrD",
        "outputId": "f663ebfb-e7b8-4004-c6d4-2c20ee2dcf15"
      },
      "source": [
        "image, label = dataset[4]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label:', label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9_3xuVhGEDR"
      },
      "source": [
        "It's evident that these images are relatively small in size, and recognizing the digits can sometimes be challenging even for the human eye. While it's useful to look at these images, there's just one problem here: PyTorch doesn't know how to work with images. We need to convert the images into tensors. We can do this by specifying a transform while creating our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqT65ZqjE8jL"
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IxZCKTrH_ay"
      },
      "source": [
        "PyTorch datasets allow us to specify one or more transformation functions that are applied to the images as they are loaded. The torchvision.transforms module contains many such predefined functions. We'll use the ToTensor transform to convert images into PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isTPE8X3H8Gj",
        "outputId": "cb724ea9-80e2-440d-fc6c-1f2a02fd4794"
      },
      "source": [
        "dataset = MNIST(root='data', train=True, transform=transforms.ToTensor())\n",
        "\n",
        "img_tensor, label = dataset[0]\n",
        "\n",
        "img_tensor.shape, label"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlHL153OIzU9"
      },
      "source": [
        "The image is now converted to a 1x28x28 tensor. The first dimension tracks color channels. The second and third dimensions represent pixels along the height and width of the image, respectively. Since images in the MNIST dataset are grayscale, there's just one channel. Other datasets have images with color, in which case there are three channels: red, green, and blue (RGB). \n",
        "\n",
        "Let's look at some sample values inside the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsMuS994IdhY",
        "outputId": "7a85285c-09fe-4a38-82e0-448d9fd2b09e"
      },
      "source": [
        "print(img_tensor[0, 5:15, 5:15])\n",
        "print(f\"max: {torch.max(img_tensor)}, min: {torch.min(img_tensor)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706,\n",
            "         0.0706],\n",
            "        [0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922,\n",
            "         0.9922],\n",
            "        [0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "         0.9922],\n",
            "        [0.0000, 0.0000, 0.0706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "         0.7765],\n",
            "        [0.0000, 0.0000, 0.0000, 0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039,\n",
            "         0.0431],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451,\n",
            "         0.0078],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922,\n",
            "         0.2745],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451,\n",
            "         0.8824],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176,\n",
            "         0.9412]])\n",
            "max: 1.0, min: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKxVYFPMJh32"
      },
      "source": [
        "The values range from 0 to 1, with `0` representing black, `1` white, and the values in between different shades of grey. We can also plot the tensor as an image using `plt.imshow`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FJu3gYEiJV01",
        "outputId": "a311fac6-9e17-4691-ccdf-78306fccfc51"
      },
      "source": [
        "# Plot the image by passing in the 28x28 matrix\n",
        "plt.imshow(img_tensor[0, 5:15, 5:15], cmap='gray')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f54c1e1edd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JlSwUwXLKOL0",
        "outputId": "4ed9ffe4-3119-4842-ca41-b2f90eb6bf25"
      },
      "source": [
        "plt.imshow(img_tensor[0], cmap='gray')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f54c183d7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1wYvjEWLh2D"
      },
      "source": [
        "Note that we need to pass just the 28x28 matrix to `plt.imshow`, without a channel dimension. We also pass a color map (`cmap=gray`) to indicate that we want to see a grayscale image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz-KMtgkLnNH"
      },
      "source": [
        "## Training and Validation Datasets\n",
        "\n",
        "While building real-world machine learning models, it is quite common to split the dataset into three parts:\n",
        "\n",
        "1. **Training set** - used to train the model, i.e., compute the loss and adjust the model's weights using gradient descent.\n",
        "2. **Validation set** - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model.\n",
        "3. **Test set** - used to compare different models or approaches and report the model's final accuracy.\n",
        "\n",
        "In the MNIST dataset, there are 60,000 training images and 10,000 test images. The test set is standardized so that different researchers can report their models' results against the same collection of images. \n",
        "\n",
        "Since there's no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let's set aside 10,000 randomly chosen images for validation. We can do this using the `random_spilt` method from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0fCu5X2KZWE",
        "outputId": "efcf438f-66e1-46c5-a494-cab1c2e74ae8"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YceLhxFsPvDT"
      },
      "source": [
        "It's essential to choose a random sample for creating a validation set. Training data is often sorted by the target labels, i.e., images of 0s, followed by 1s, followed by 2s, etc. If we create a validation set using the last 20% of images, it would only consist of 8s and 9s. In contrast, the training set would contain no 8s or 9s. Such a training-validation would make it impossible to train a useful model.\n",
        "\n",
        "We can now create data loaders to help us load the data in batches. We'll use a batch size of 128.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgsyUiIRKh6z"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_-JefvRQk1Z"
      },
      "source": [
        "We set `shuffle=True` for the training data loader to ensure that the batches generated in each epoch are different. This randomization helps generalize & speed up the training process. On the other hand, since the validation data loader is used only for evaluating the model, there is no need to shuffle the images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-elJhEA7QkJD"
      },
      "source": [
        "jovia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "954-11YxZZJR"
      },
      "source": [
        "## Model\n",
        "\n",
        "Now that we have prepared our data loaders, we can define our model.\n",
        "\n",
        "* A **logistic regression** model is almost identical to a linear regression model. It contains weights and bias matrices, and the output is obtained using simple matrix operations (`pred = x @ w.t() + b`). \n",
        "\n",
        "* As we did with linear regression, we can use `nn.Linear` to create the model instead of manually creating and initializing the matrices.\n",
        "\n",
        "* Since `nn.Linear` expects each training example to be a vector, each `1x28x28` image tensor is _flattened_ into a vector of size 784 `(28*28)` before being passed into the model. \n",
        "\n",
        "* The output for each image is a vector of size 10, with each element signifying the probability of a particular target label (i.e., 0 to 9). The predicted label for an image is simply the one with the highest probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeVUMldEZbAs"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_size = 28 * 28\n",
        "num_classes = 10\n",
        "\n",
        "# Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFpUutFkmVaf"
      },
      "source": [
        "Let's take a look at the weights and biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmGKa8NlmU3O",
        "outputId": "299e7e36-ed47-4487-f9ce-95de768069ee"
      },
      "source": [
        "# weights\n",
        "print(model.weight.shape)\n",
        "print(model.weight)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0139,  0.0118,  0.0230,  ...,  0.0098, -0.0193,  0.0248],\n",
            "        [-0.0316, -0.0173,  0.0140,  ..., -0.0186,  0.0072, -0.0141],\n",
            "        [-0.0156, -0.0121,  0.0301,  ..., -0.0019,  0.0062, -0.0296],\n",
            "        ...,\n",
            "        [ 0.0174, -0.0075, -0.0107,  ..., -0.0290, -0.0213, -0.0256],\n",
            "        [ 0.0221, -0.0290,  0.0348,  ..., -0.0210,  0.0134, -0.0233],\n",
            "        [ 0.0197, -0.0318,  0.0043,  ..., -0.0242,  0.0063,  0.0117]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD-RvlTlmelv",
        "outputId": "2dccc95e-f72e-46a9-d1ab-ad7688fd2ede"
      },
      "source": [
        "# biases\n",
        "print(model.bias.shape)\n",
        "print(model.bias)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n",
            "Parameter containing:\n",
            "tensor([ 0.0357, -0.0177,  0.0121,  0.0031, -0.0058, -0.0017, -0.0273,  0.0215,\n",
            "        -0.0241,  0.0068], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxoUw-t0m2DO"
      },
      "source": [
        "Although there are a total of 7850 parameters here, conceptually, nothing has changed so far. Let's try and generate some outputs using our model. We'll take the first batch of 100 images from our dataset and pass them into our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "erJ0cTURmu2H",
        "outputId": "1a1b6f7b-9997-4b5e-ebd0-b3e07cdc2458"
      },
      "source": [
        "for image, label in train_loader:\n",
        "  print(label)\n",
        "  print(image.shape)\n",
        "  output = model(image)\n",
        "  print(output)\n",
        "  break"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([8, 8, 3, 7, 9, 7, 9, 7, 3, 3, 3, 9, 1, 2, 5, 7, 5, 2, 7, 4, 8, 9, 1, 3,\n",
            "        1, 6, 0, 1, 4, 5, 5, 8, 5, 5, 0, 3, 0, 8, 1, 3, 3, 1, 0, 3, 7, 5, 6, 2,\n",
            "        4, 3, 6, 2, 4, 8, 8, 3, 4, 1, 9, 8, 9, 2, 5, 7, 2, 5, 8, 7, 3, 7, 4, 0,\n",
            "        3, 1, 7, 3, 8, 7, 1, 1, 3, 1, 9, 8, 2, 6, 2, 7, 6, 6, 6, 6, 8, 1, 5, 2,\n",
            "        1, 0, 2, 5, 4, 6, 5, 4, 9, 5, 9, 9, 4, 4, 9, 9, 8, 3, 2, 5, 4, 0, 1, 8,\n",
            "        9, 5, 3, 3, 3, 3, 1, 3])\n",
            "torch.Size([128, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-95d54eb83607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxT3W27Mnjcv",
        "outputId": "84829a8a-187b-454c-ff25-ea59dc802ab7"
      },
      "source": [
        "image.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Rrd4WJn11e",
        "outputId": "e784bab9-fc51-4ba3-b387-7a27c29c3d50"
      },
      "source": [
        "image.reshape(-1, 28*28).shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIMGDDTxoT4x"
      },
      "source": [
        "The code above leads to an error because our input data does not have the right shape. Our images are of the shape 1x28x28, but we need them to be vectors of size 784, i.e., we need to flatten them. We'll use the `.reshape` method of a tensor, which will allow us to efficiently 'view' each image as a flat vector without really creating a copy of the underlying data. To include this additional functionality within our model, we need to define a custom model by extending the `nn.Module` class from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpG7RLY8oBOs"
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    xb = xb.reshape(-1, 28*28)\n",
        "    out = self.linear(xb)\n",
        "    return out\n",
        "\n",
        "model = MnistModel()\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU36QQQZqMfi"
      },
      "source": [
        "Inside the `__init__` constructor method, we instantiate the weights and biases using `nn.Linear`. And inside the `forward` method, which is invoked when we pass a batch of inputs to the model, we flatten the input tensor and pass it into `self.linear`.\n",
        "\n",
        "`xb.reshape(-1, 28*28)` indicates to PyTorch that we want a *view* of the `xb` tensor with two dimensions. The length along the 2nd dimension is 28\\*28 (i.e., 784). One argument to `.reshape` can be set to `-1` (in this case, the first dimension) to let PyTorch figure it out automatically based on the shape of the original tensor.\n",
        "\n",
        "Note that the model no longer has `.weight` and `.bias` attributes (as they are now inside the `.linear` attribute), but it does have a `.parameters` method that returns a list containing the weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcLKDFX7ptge",
        "outputId": "0efee8b8-cc10-4f53-db07-c6b1091d37c0"
      },
      "source": [
        "print(model.linear)\n",
        "print('***' * 20)\n",
        "print(model.linear.weight.shape, model.linear.bias.shape)\n",
        "print('---' * 20)\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=10, bias=True)\n",
            "************************************************************\n",
            "torch.Size([10, 784]) torch.Size([10])\n",
            "------------------------------------------------------------\n",
            "[Parameter containing:\n",
            "tensor([[-0.0296,  0.0182, -0.0285,  ..., -0.0134, -0.0342,  0.0066],\n",
            "        [-0.0285,  0.0273,  0.0046,  ...,  0.0014,  0.0332,  0.0323],\n",
            "        [ 0.0029,  0.0347, -0.0039,  ...,  0.0089, -0.0035, -0.0225],\n",
            "        ...,\n",
            "        [-0.0204,  0.0315, -0.0040,  ...,  0.0288,  0.0273, -0.0209],\n",
            "        [ 0.0088, -0.0019, -0.0340,  ...,  0.0006,  0.0018,  0.0153],\n",
            "        [ 0.0120,  0.0196, -0.0320,  ...,  0.0263,  0.0105,  0.0252]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0259, -0.0028,  0.0205,  0.0294,  0.0115, -0.0149, -0.0324, -0.0249,\n",
            "        -0.0051, -0.0295], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z0ZRYm9rMB_"
      },
      "source": [
        "Now, we can use our new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PXpBo5rqvBc",
        "outputId": "a87abfe1-f043-41fe-bcd2-a9a89e8adaa3"
      },
      "source": [
        "for image, label in train_loader:\n",
        "  print(label)\n",
        "  print('****' * 20)\n",
        "  print(image.shape)\n",
        "  print('****' * 20)\n",
        "  out = model(image)\n",
        "  break\n",
        "print(f\"out.shape: {out.shape}\")\n",
        "print(f\"sample of data: {out[:2].data}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 8, 9, 7, 7, 6, 7, 4, 2, 2, 9, 1, 9, 0, 1, 5, 3, 4, 2, 4, 6, 8, 8, 8,\n",
            "        1, 6, 1, 5, 2, 7, 4, 1, 1, 4, 3, 6, 4, 8, 8, 1, 2, 1, 8, 9, 1, 3, 8, 0,\n",
            "        6, 3, 6, 8, 0, 5, 1, 0, 4, 6, 3, 2, 8, 9, 0, 6, 2, 3, 2, 3, 0, 4, 8, 8,\n",
            "        9, 3, 2, 3, 1, 5, 1, 5, 4, 3, 6, 6, 6, 5, 9, 9, 6, 2, 0, 8, 6, 4, 9, 3,\n",
            "        0, 0, 2, 9, 9, 0, 7, 8, 2, 0, 2, 4, 1, 6, 9, 1, 0, 8, 0, 3, 8, 0, 8, 4,\n",
            "        9, 2, 2, 0, 9, 6, 7, 5])\n",
            "********************************************************************************\n",
            "torch.Size([128, 1, 28, 28])\n",
            "********************************************************************************\n",
            "out.shape: torch.Size([128, 10])\n",
            "sample of data: tensor([[-0.1983, -0.2575,  0.1665, -0.1546,  0.4370,  0.1092, -0.2311,  0.0780,\n",
            "          0.1351, -0.2756],\n",
            "        [-0.0927, -0.2351,  0.1995, -0.1635,  0.3479, -0.0803, -0.2662,  0.0222,\n",
            "         -0.1330, -0.3586]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuHP9Hrw2Lw8"
      },
      "source": [
        "For each of the 100 input images, we get 10 outputs, one for each class. As discussed earlier, we'd like these outputs to represent probabilities. Each output row's elements must lie between 0 to 1 and add up to 1, which is not the case. \n",
        "\n",
        "To convert the output rows into probabilities, we use the softmax function, which has the following formula:\n",
        "\n",
        "![softmax](https://i.imgur.com/EAh9jLN.png)\n",
        "\n",
        "First, we replace each element `yi` in an output row by `e^yi`, making all the elements positive. \n",
        "\n",
        "![](https://www.montereyinstitute.org/courses/DevelopmentalMath/COURSE_TEXT2_RESOURCE/U18_L1_T1_text_final_6_files/image001.png)\n",
        "\n",
        "\n",
        "\n",
        "Then, we divide them by their sum to ensure that they add up to 1. The resulting vector can thus be interpreted as probabilities.\n",
        "\n",
        "While it's easy to implement the softmax function (you should try it!), we'll use the implementation that's provided within PyTorch because it works well with multidimensional tensors (a list of output rows in our case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbSVmEcrriTf"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-miO02s7bK-"
      },
      "source": [
        "The softmax function is included in the `torch.nn.functional` package and requires us to specify a dimension along which the function should be applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVTb1sWOtWTs",
        "outputId": "a0a755f9-f2cd-4c0b-e50f-20a5e7e20591"
      },
      "source": [
        "out[:2]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1983, -0.2575,  0.1665, -0.1546,  0.4370,  0.1092, -0.2311,  0.0780,\n",
              "          0.1351, -0.2756],\n",
              "        [-0.0927, -0.2351,  0.1995, -0.1635,  0.3479, -0.0803, -0.2662,  0.0222,\n",
              "         -0.1330, -0.3586]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg7A9Lli7mGv",
        "outputId": "57c607ac-cb08-4f0c-856a-99f78f1ed451"
      },
      "source": [
        "# Apply softmax for each output row\n",
        "probs = F.softmax(out, dim=1)\n",
        "\n",
        "# Look at sample probabilities\n",
        "print(f\"Samples of probs: {probs[:2].data}\")\n",
        "\n",
        "# Add up the probabilities of an output row\n",
        "print(f\"Sum of probs: {torch.sum(probs[0]).item()}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples of probs: tensor([[0.0814, 0.0767, 0.1173, 0.0851, 0.1537, 0.1107, 0.0788, 0.1073, 0.1136,\n",
            "         0.0754],\n",
            "        [0.0962, 0.0834, 0.1289, 0.0896, 0.1495, 0.0974, 0.0809, 0.1079, 0.0924,\n",
            "         0.0738]])\n",
            "Sum of probs: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-0yVqa88lfC"
      },
      "source": [
        "Finally, we can determine the predicted label for each image by simply choosing the index of the element with the highest probability in each output row. We can do this using `torch.max`, which returns each row's largest element and the corresponding index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL7OZdke8UpS",
        "outputId": "2d1df8cd-2734-457a-833f-a45e38a94986"
      },
      "source": [
        "max_probs, preds = torch.max(probs, dim=1)\n",
        "print(preds)\n",
        "print(max_probs)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4, 4, 4, 4, 4, 5, 4, 7, 5, 4, 5, 2, 4, 0, 8, 4, 4, 4, 4, 4, 0, 7, 4, 4,\n",
            "        4, 7, 7, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 8, 4, 3, 4, 4, 4, 2,\n",
            "        3, 4, 5, 4, 4, 4, 8, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 5, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 6, 5, 4, 4, 4, 0, 4, 4, 4, 2, 5, 5, 4, 4, 4, 3, 7,\n",
            "        2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 2, 4, 5, 3, 4])\n",
            "tensor([0.1537, 0.1495, 0.1737, 0.1437, 0.1576, 0.1438, 0.1425, 0.1225, 0.1554,\n",
            "        0.1514, 0.1488, 0.1139, 0.1554, 0.1227, 0.1165, 0.1392, 0.1252, 0.1407,\n",
            "        0.1538, 0.1164, 0.1238, 0.1394, 0.1590, 0.1434, 0.1200, 0.1327, 0.1197,\n",
            "        0.1337, 0.1280, 0.1348, 0.1318, 0.1263, 0.1536, 0.1418, 0.1609, 0.1705,\n",
            "        0.1207, 0.1301, 0.1415, 0.1237, 0.1611, 0.1158, 0.1296, 0.1257, 0.1337,\n",
            "        0.1553, 0.1498, 0.1294, 0.1332, 0.1509, 0.1493, 0.1666, 0.1468, 0.1328,\n",
            "        0.1146, 0.1408, 0.1387, 0.1494, 0.1401, 0.1320, 0.1491, 0.1356, 0.1331,\n",
            "        0.1464, 0.1306, 0.1553, 0.1143, 0.1482, 0.1625, 0.1342, 0.1482, 0.1538,\n",
            "        0.1597, 0.1557, 0.1335, 0.1406, 0.1217, 0.1350, 0.1314, 0.1152, 0.1409,\n",
            "        0.1597, 0.1265, 0.1454, 0.1302, 0.1640, 0.1416, 0.1470, 0.1238, 0.1286,\n",
            "        0.1396, 0.1542, 0.1446, 0.1284, 0.1244, 0.1276, 0.1318, 0.1334, 0.1331,\n",
            "        0.1179, 0.1414, 0.1331, 0.1542, 0.1747, 0.1257, 0.1307, 0.1231, 0.1209,\n",
            "        0.1348, 0.1404, 0.1269, 0.1443, 0.1236, 0.1325, 0.1365, 0.1587, 0.1584,\n",
            "        0.1450, 0.1639, 0.1127, 0.1533, 0.1454, 0.1449, 0.1261, 0.1425, 0.1268,\n",
            "        0.1191, 0.1334], grad_fn=<MaxBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRadW-A29D9t"
      },
      "source": [
        "The numbers printed above are the predicted labels for the first batch of training images. Let's compare them with the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh5b-TDL86Rx",
        "outputId": "7a42bcac-2f2e-442f-fd58-3599af0e9e77"
      },
      "source": [
        "print(label)\n",
        "print(preds)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 8, 9, 7, 7, 6, 7, 4, 2, 2, 9, 1, 9, 0, 1, 5, 3, 4, 2, 4, 6, 8, 8, 8,\n",
            "        1, 6, 1, 5, 2, 7, 4, 1, 1, 4, 3, 6, 4, 8, 8, 1, 2, 1, 8, 9, 1, 3, 8, 0,\n",
            "        6, 3, 6, 8, 0, 5, 1, 0, 4, 6, 3, 2, 8, 9, 0, 6, 2, 3, 2, 3, 0, 4, 8, 8,\n",
            "        9, 3, 2, 3, 1, 5, 1, 5, 4, 3, 6, 6, 6, 5, 9, 9, 6, 2, 0, 8, 6, 4, 9, 3,\n",
            "        0, 0, 2, 9, 9, 0, 7, 8, 2, 0, 2, 4, 1, 6, 9, 1, 0, 8, 0, 3, 8, 0, 8, 4,\n",
            "        9, 2, 2, 0, 9, 6, 7, 5])\n",
            "tensor([4, 4, 4, 4, 4, 5, 4, 7, 5, 4, 5, 2, 4, 0, 8, 4, 4, 4, 4, 4, 0, 7, 4, 4,\n",
            "        4, 7, 7, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 8, 4, 3, 4, 4, 4, 2,\n",
            "        3, 4, 5, 4, 4, 4, 8, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 5, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 6, 5, 4, 4, 4, 0, 4, 4, 4, 2, 5, 5, 4, 4, 4, 3, 7,\n",
            "        2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 2, 4, 5, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2QhWAFi9RZV"
      },
      "source": [
        "Most of the predicted labels are different from the actual labels. That's because we have started with randomly initialized weights and biases. We need to train the model, i.e., adjust the weights using gradient descent to make better predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPcQRNnp9c6Z"
      },
      "source": [
        "## Evaluation Metric and Loss Function\n",
        "Just as with linear regression, we need a way to evaluate how well our model is performing. A natural way to do this would be to find the percentage of labels that were predicted correctly, i.e,. the **accuracy** of the predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEVitJsh9GxH",
        "outputId": "0e6b6c3a-3805-45e0-d337-495d56eef55e"
      },
      "source": [
        "out[:2]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1983, -0.2575,  0.1665, -0.1546,  0.4370,  0.1092, -0.2311,  0.0780,\n",
              "          0.1351, -0.2756],\n",
              "        [-0.0927, -0.2351,  0.1995, -0.1635,  0.3479, -0.0803, -0.2662,  0.0222,\n",
              "         -0.1330, -0.3586]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNUx8c069rtt",
        "outputId": "1ec60ee2-c358-48df-baa6-a910b1f7de16"
      },
      "source": [
        "torch.sum(label==preds)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_xiVZ5G94nZ",
        "outputId": "67ddbcbe-6562-4495-c6ac-da4703e733ea"
      },
      "source": [
        "label == preds"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False,  True, False, False, False,  True, False,  True,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False,  True, False, False,  True, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False,  True, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False,  True, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,  True,\n",
              "        False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVxi5zAn98fB",
        "outputId": "fa8b6276-9df5-4421-f034-fc1ef359506d"
      },
      "source": [
        "torch.sum(label==preds).item()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvsY3iDR-Kxm",
        "outputId": "dd330996-b99c-4e9e-dfef-92d253b7291e"
      },
      "source": [
        "len(preds)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saFb9Mhy-Sbi",
        "outputId": "ab9bf37c-e654-463c-9f19-6684ebe78551"
      },
      "source": [
        "torch.sum(label==preds).item() / len(preds)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nP7T3ZP-XHo"
      },
      "source": [
        "def accuracy(out, label):\n",
        "  _, preds = torch.max(out, dim=1)\n",
        "  return torch.tensor(torch.sum(label==preds).item() / len(preds))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5z2Yq6K_Zmc"
      },
      "source": [
        "The `==` operator performs an element-wise comparison of two tensors with the same shape and returns a tensor of the same shape, containing `False` for unequal elements and `True` for equal elements. Passing the result to `torch.sum` returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy. \n",
        "\n",
        "Note that we don't need to apply softmax to the outputs since its results have the same relative order. This is because `e^x` is an increasing function, i.e., if `y1 > y2`, then `e^y1 > e^y2`. The same holds after averaging out the values to get the softmax.\n",
        "\n",
        "Let's calculate the accuracy of the current model on the first batch of data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JgI_G1F_Yna",
        "outputId": "a042fad2-085b-48e6-c38f-a268b656220a"
      },
      "source": [
        "accuracy(out, label)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLmCiFOw_kG_",
        "outputId": "01b7780d-75fd-4514-e450-a6412a73ff58"
      },
      "source": [
        "probs"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0814, 0.0767, 0.1173,  ..., 0.1073, 0.1136, 0.0754],\n",
              "        [0.0962, 0.0834, 0.1289,  ..., 0.1079, 0.0924, 0.0738],\n",
              "        [0.0888, 0.0916, 0.0875,  ..., 0.0821, 0.0897, 0.0586],\n",
              "        ...,\n",
              "        [0.0992, 0.0797, 0.1047,  ..., 0.0924, 0.1004, 0.0764],\n",
              "        [0.1017, 0.0869, 0.0967,  ..., 0.1162, 0.1029, 0.0693],\n",
              "        [0.0890, 0.0915, 0.0990,  ..., 0.1013, 0.1280, 0.0880]],\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK8zailS_zjF"
      },
      "source": [
        "Accuracy is an excellent way for us (humans) to evaluate the model. However, we can't use it as a loss function for optimizing our model using gradient descent for the following reasons:\n",
        "\n",
        "1. It's not a differentiable function. `torch.max` and `==` are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n",
        "\n",
        "2. It doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements. \n",
        "\n",
        "For these reasons, accuracy is often used as an **evaluation metric** for classification, but not as a loss function. A commonly used loss function for classification problems is the **cross-entropy**, which has the following formula:\n",
        "\n",
        "![cross-entropy](https://i.imgur.com/VDRDl1D.png)\n",
        "\n",
        "While it looks complicated, it's actually quite simple:\n",
        "\n",
        "* For each output row, pick the predicted probability for the correct label. E.g., if the predicted probabilities for an image are `[0.1, 0.3, 0.2, ...]` and the correct label is `1`, we pick the corresponding element `0.3` and ignore the rest.\n",
        "\n",
        "* Then, take the [logarithm](https://en.wikipedia.org/wiki/Logarithm) of the picked probability. If the probability is high, i.e., close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n",
        "\n",
        "![](https://www.intmath.com/blog/wp-content/images/2019/05/log10.png)\n",
        "\n",
        "* Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n",
        "\n",
        "Unlike accuracy, cross-entropy is a continuous and differentiable function. It also provides useful feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). These two factors make cross-entropy a better choice for the loss function.\n",
        "\n",
        "As you might expect, PyTorch provides an efficient and tensor-friendly implementation of cross-entropy as part of the `torch.nn.functional` package. Moreover, it also performs softmax internally, so we can directly pass in the model's outputs without converting them into probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXGeVJUK_t9h",
        "outputId": "5d7d5bde-2681-4b62-8bf1-6a265a4b58d4"
      },
      "source": [
        "out"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1983, -0.2575,  0.1665,  ...,  0.0780,  0.1351, -0.2756],\n",
              "        [-0.0927, -0.2351,  0.1995,  ...,  0.0222, -0.1330, -0.3586],\n",
              "        [-0.0561, -0.0254, -0.0705,  ..., -0.1348, -0.0458, -0.4722],\n",
              "        ...,\n",
              "        [-0.1093, -0.3281, -0.0553,  ..., -0.1800, -0.0969, -0.3700],\n",
              "        [ 0.0508, -0.1066,  0.0010,  ...,  0.1842,  0.0623, -0.3333],\n",
              "        [-0.0477, -0.0210,  0.0583,  ...,  0.0810,  0.3152, -0.0589]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e5l_aAoAmtg"
      },
      "source": [
        "loss_fn = F.cross_entropy"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTxy136sAtUa",
        "outputId": "92196772-2ead-4653-c548-4430b2b0684d"
      },
      "source": [
        "# Loss for current batch of data\n",
        "loss = loss_fn(out, preds)\n",
        "loss"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.9793, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kia95HFYA8nu"
      },
      "source": [
        "We know that cross-entropy is the negative logarithm of the predicted probability of the correct label averaged over all training samples. Therefore, one way to interpret the resulting number e.g. `2.23` is look at `e^-2.23` which is around `0.1` as the predicted probability of the correct label, on average. *The lower the loss, The better the model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoIiL0udBO7S"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now that we have defined the data loaders, model, loss function and optimizer, we are ready to train the model. The training process is identical to linear regression, with the addition of a \"validation phase\" to evaluate the model in each epoch. Here's what it looks like in pseudocode:\n",
        "\n",
        "```\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    for batch in train_loader:\n",
        "        # Generate predictions\n",
        "        # Calculate loss\n",
        "        # Compute gradients\n",
        "        # Update weights\n",
        "        # Reset gradients\n",
        "    \n",
        "    # Validation phase\n",
        "    for batch in val_loader:\n",
        "        # Generate predictions\n",
        "        # Calculate loss\n",
        "        # Calculate metrics (accuracy etc.)\n",
        "    # Calculate average validation loss & metrics\n",
        "    \n",
        "    # Log epoch, loss & metrics for inspection\n",
        "```\n",
        "\n",
        "Some parts of the training loop are specific the specific problem we're solving (e.g. loss function, metrics etc.) whereas others are generic and can be applied to any deep learning problem. \n",
        "\n",
        "We'll include the problem-independent parts within a function called `fit`, which will be used to train the model. The problem-specific parts will be implemented by adding new methods to the `nn.Module` class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKXvV7SiA4AB"
      },
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    history = [] # for recording epoch-wise results\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmOvzcJICL-Q"
      },
      "source": [
        "The `fit` function records the validation loss and metric from each epoch. It returns a history of the training, useful for debugging & visualization.\n",
        "\n",
        "Configurations like batch size, learning rate, etc. (called hyperparameters), need to picked in advance while training machine learning models. Choosing the right hyperparameters is critical for training a reasonably accurate model within a reasonable amount of time. It is an active area of research and experimentation in machine learning. Feel free to try different learning rates and see how it affects the training process.\n",
        "\n",
        "\n",
        "Let's define the `evaluate` function, used in the validation phase of `fit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwD6XfxmCFgm"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWpmjCpBDNxq"
      },
      "source": [
        "\n",
        "Finally, let's redefine the `MnistModel` class to include additional methods `training_step`, `validation_step`, `validation_epoch_end`, and `epoch_end` used by `fit` and `evaluate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DVlim2oDH76"
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        xb = xb.reshape(-1, 784)\n",
        "        out = self.linear(xb)\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "    \n",
        "model = MnistModel()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6x4MVqRDVad"
      },
      "source": [
        "Before we train the model, let's see how the model performs on the validation set with the initial set of randomly initialized weights & biases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXxkeOAdDRRg",
        "outputId": "978ca4eb-4849-45e6-b62b-62a5410ea0fc"
      },
      "source": [
        "result0 = evaluate(model, val_loader)\n",
        "result0"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.09266218543052673, 'val_loss': 2.323948621749878}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIGW-H7MD2M3"
      },
      "source": [
        "The initial accuracy is around 9%, which one might expect from a randomly initialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n",
        "\n",
        "We are now ready to train the model. Let's train for five epochs and look at the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsmTB_ejDY9x",
        "outputId": "626f272c-663b-48c9-a848-42b6ea64ecd3"
      },
      "source": [
        "history1 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 1.9542, val_acc: 0.6117\n",
            "Epoch [1], val_loss: 1.6856, val_acc: 0.7122\n",
            "Epoch [2], val_loss: 1.4849, val_acc: 0.7486\n",
            "Epoch [3], val_loss: 1.3332, val_acc: 0.7720\n",
            "Epoch [4], val_loss: 1.2166, val_acc: 0.7880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THO-XAZ7ENk0"
      },
      "source": [
        "That's a great result! With just 5 epochs of training, our model has reached an accuracy of over 79% on the validation set. Let's see if we can improve that by training for a few more epochs. Try changing the learning rates and number of epochs in each of the cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuzzMjfED68O",
        "outputId": "864ebcb5-d9e2-4d11-8aa4-ce0043795c8e"
      },
      "source": [
        "history2 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 1.1248, val_acc: 0.7988\n",
            "Epoch [1], val_loss: 1.0511, val_acc: 0.8091\n",
            "Epoch [2], val_loss: 0.9908, val_acc: 0.8172\n",
            "Epoch [3], val_loss: 0.9406, val_acc: 0.8231\n",
            "Epoch [4], val_loss: 0.8981, val_acc: 0.8280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zalgB4rGEUnI",
        "outputId": "74f9d6b3-98e5-488c-a3eb-9e1895f67902"
      },
      "source": [
        "history3 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.8193, val_acc: 0.8376\n",
            "Epoch [1], val_loss: 0.7930, val_acc: 0.8405\n",
            "Epoch [2], val_loss: 0.7697, val_acc: 0.8429\n",
            "Epoch [3], val_loss: 0.7489, val_acc: 0.8445\n",
            "Epoch [4], val_loss: 0.7301, val_acc: 0.8466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd3J6ZpcEa9X",
        "outputId": "38782e08-c9d2-49f1-93d0-552e65b08b0c"
      },
      "source": [
        "history4 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.7132, val_acc: 0.8478\n",
            "Epoch [1], val_loss: 0.6979, val_acc: 0.8499\n",
            "Epoch [2], val_loss: 0.6838, val_acc: 0.8508\n",
            "Epoch [3], val_loss: 0.6709, val_acc: 0.8524\n",
            "Epoch [4], val_loss: 0.6591, val_acc: 0.8536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D3tteL7EyxM"
      },
      "source": [
        "While the accuracy does continue to increase as we train for more epochs, the improvements get smaller with every epoch. Let's visualize this using a line graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "zhEjiYZnEo21",
        "outputId": "3218f70a-a765-491b-c905-2aa333ef024f"
      },
      "source": [
        "history = [result0] + history1 + history2 + history3 + history4\n",
        "accuracies = [result['val_acc'] for result in history]\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(accuracies, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpJADc6oFyny"
      },
      "source": [
        "It's quite clear from the above picture that the model probably won't cross the accuracy threshold of 90% even after training for a very long time. One possible reason for this is that the learning rate might be too high. The model's parameters may be \"bouncing\" around the optimal set of parameters for the lowest loss. You can try reducing the learning rate and training for a few more epochs to see if it helps.\n",
        "\n",
        "The more likely reason that **the model just isn't powerful enough**. If you remember our initial hypothesis, we have assumed that the output (in this case the class probabilities) is a **linear function** of the input (pixel intensities), obtained by perfoming a matrix multiplication with the weights matrix and adding the bias. This is a fairly weak assumption, as there may not actually exist a linear relationship between the pixel intensities in an image and the digit it represents. While it works reasonably well for a simple dataset like MNIST (getting us to 85% accuracy), we need more sophisticated models that can capture non-linear relationships between image pixels and labels for complex tasks like recognizing everyday objects, animals etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "cbxYNSQOE4Ee",
        "outputId": "084b3172-d078-43f4-89a4-9eeaf35e0415"
      },
      "source": [
        "jovian.log_metrics(val_acc=history[-1]['val_acc'], val_loss=history[-1]['val_loss'])\n",
        "jovian.commit(project='images-and-logistic-regression', environment=None)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Metrics logged.\u001b[0m\n",
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/boubekri/images-and-logistic-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/boubekri/images-and-logistic-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3pEF-7GPwh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}